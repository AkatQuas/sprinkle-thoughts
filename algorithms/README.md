# Teach yourself something about Algorithms

Keep digging into the black box of Algorithms, based on the `Introduction of Algorithms - MIT MOOC`.

## Contents:
* [Asymptotic Analysis](#asymptotic-analysis)
* [Recurse and Iteration](#recurse-and-iteration)
* [Divide and Conquer](#divide-and-conquer)

## Asymptotic Analysis
Big O notation, the time T, or the Omega notation
* Exponential worst.
* Polynomial is soso, and mostly naive algorithm can achieve 
* Logarithmic\*Polymonial is kind of ok, as a subsitition to lower the Polynomial dimension
* Logarithmic is great, try to come up with this kind of algorithms 
* Constant best whilst rarely achieved

- The cost are different in Product and Add. It is a good idea to use Add instead of Product

## Recurse and Iteration
They are two similar ways designed to solve problems in loops. The differences is subtle. `Iteration` is more clear and easy to understand, while `Recurse` requires some tricks and is more efficient in dealing with problems which can be easily inducted in the idea of `Mathematics Induction`.
`Induction` is important in solving problems in loops. Keep that in mind. To write a recursive algorithms, be aware of the base case and the induction.

## Divide and Conquer
Basically 3 steps: 
1. Divide the BIG PROBLEM into similar small problems
2. Conquer each small problems. Since they are quite similar, recurse or iteration is recommended.
3. Combine all the solution or results, the BIG PROBLEM is conquered in the end.

In the step 2, you can find the tricky usage of `Induction`. And that is the reason why once divided problems are solved and the BIG ONE is solved naturally.  


